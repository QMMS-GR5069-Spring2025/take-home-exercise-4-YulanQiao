{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22d910d0-7070-4382-9959-8cc39acfad3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85cfb00c-76e7-41d6-8003-5cc7927024f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_results = spark.read.csv('s3://columbia-gr5069-main/raw/results.csv', header=True, inferSchema=True)\n",
    "df_races = spark.read.csv('s3://columbia-gr5069-main/raw/races.csv', header=True, inferSchema=True)\n",
    "df_drivers = spark.read.csv('s3://columbia-gr5069-main/raw/drivers.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a7b652-5a73-4712-a5a7-eb320207289f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS yq2396_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e89b11e-0fe5-4246-b2ff-fff8247fdf1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df_results = df_results.withColumn(\n",
    "    \"label\", when(col(\"positionOrder\") <= 3, 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9db2a613-8919-4561-a691-e64e6ad2b9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_results.join(df_races, on=\"raceId\", how=\"left\") \\\n",
    "                      .join(df_drivers, on=\"driverId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f0e2f0-ff8c-45cf-899d-8f53356170b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"grid\", \"laps\", \"statusId\"]  \n",
    "\n",
    "vec = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_model = vec.transform(df_joined).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b52a239c-0426-4e0c-b30d-c61018a812be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = df_model.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99195e24-1415-4e90-aded-795869b18c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Logistic regression \n",
    "\n",
    "# Train model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogReg_Top3\"):\n",
    "\n",
    "    # Fit model\n",
    "    model_lr = lr.fit(train_data)\n",
    "    preds_lr = model_lr.transform(test_data)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.spark.log_model(model_lr, \"logreg_model\")\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"maxIter\", 100)\n",
    "    mlflow.log_param(\"regParam\", 0.0)\n",
    "\n",
    "    # Log metrics\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator.evaluate(preds_lr)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "    multiclass_eval = MulticlassClassificationEvaluator(labelCol=\"label\")\n",
    "    mlflow.log_metric(\"accuracy\", multiclass_eval.evaluate(preds_lr, {multiclass_eval.metricName: \"accuracy\"}))\n",
    "    mlflow.log_metric(\"f1\", multiclass_eval.evaluate(preds_lr, {multiclass_eval.metricName: \"f1\"}))\n",
    "    mlflow.log_metric(\"precision\", multiclass_eval.evaluate(preds_lr, {multiclass_eval.metricName: \"weightedPrecision\"}))\n",
    "\n",
    "    # Log artifact: confusion matrix\n",
    "    y_true = preds_lr.select(\"label\").toPandas()\n",
    "    y_pred = preds_lr.select(\"prediction\").toPandas()\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "    plt.savefig(\"/tmp/confusion_lr.png\")\n",
    "    mlflow.log_artifact(\"/tmp/confusion_lr.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aafde7-92d1-4e82-868b-a4cfaa7616fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50, maxDepth=5)\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_Top3\"):\n",
    "\n",
    "    # Fit model\n",
    "    model_rf = rf.fit(train_data)\n",
    "    preds_rf = model_rf.transform(test_data)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.spark.log_model(model_rf, \"rf_model\")\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"numTrees\", 50)\n",
    "    mlflow.log_param(\"maxDepth\", 5)\n",
    "\n",
    "    # Log metrics\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator.evaluate(preds_rf)\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "    multiclass_eval = MulticlassClassificationEvaluator(labelCol=\"label\")\n",
    "    mlflow.log_metric(\"accuracy\", multiclass_eval.evaluate(preds_rf, {multiclass_eval.metricName: \"accuracy\"}))\n",
    "    mlflow.log_metric(\"f1\", multiclass_eval.evaluate(preds_rf, {multiclass_eval.metricName: \"f1\"}))\n",
    "    mlflow.log_metric(\"precision\", multiclass_eval.evaluate(preds_rf, {multiclass_eval.metricName: \"weightedPrecision\"}))\n",
    "\n",
    "    # Confusion matrix artifact\n",
    "    y_true_rf = preds_rf.select(\"label\").toPandas()\n",
    "    y_pred_rf = preds_rf.select(\"prediction\").toPandas()\n",
    "\n",
    "    cm_rf = confusion_matrix(y_true_rf, y_pred_rf)\n",
    "    disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
    "    disp_rf.plot()\n",
    "    plt.title(\"Confusion Matrix - Random Forest\")\n",
    "    plt.savefig(\"/tmp/confusion_rf.png\")\n",
    "    mlflow.log_artifact(\"/tmp/confusion_rf.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ed6aec-57e5-4773-b03b-2603fa5956f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preds_lr.select(\"prediction\", \"label\") \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"yq2396_db.model1_predictions\")\n",
    "\n",
    "preds_rf.select(\"prediction\", \"label\") \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"yq2396_db.model2_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7afd5b5b-ce4e-4ff5-b52a-11168d65dffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa366e5-c35a-47b4-8d8b-39c47f4ef513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM yq2396_db.model1_predictions LIMIT 5\").show()\n",
    "spark.sql(\"SELECT * FROM yq2396_db.model2_predictions LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853991ea-239d-4a5b-9e31-da980f8f064c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_model.groupBy(\"label\").count().show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "model deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
